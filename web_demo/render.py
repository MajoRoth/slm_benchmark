#!/usr/bin/env python3
"""Generate forms for human evaluation."""
import json
from pathlib import Path

from jinja2 import FileSystemLoader, Environment

from utils.dataset import EmotionDataset


def main():
    """Main function."""
    loader = FileSystemLoader(searchpath="./templates")
    env = Environment(loader=loader)
    template = env.get_template("demo.html.jinja2")

    male_sentiments = list(Path("../audio/emotion_prompts/male").glob("*.wav"))
    female_sentiments = list(Path("../audio/emotion_prompts/female").glob("*.wav"))
    classes = ["laugh", "phone", "waterfall"]

    emotions = ['happy', 'sad', 'neutral']

    speakers = [
        {'speaker': 3, 'prompt': 'concat'},
        {'speaker': 5, 'prompt': 'concat'},
        # {'speaker': 19, 'prompt': 'concat'},
        {'speaker': 23, 'prompt': 'concat'},
        {'speaker': 2, 'prompt': 'concat'},
        # {'speaker': 8, 'prompt': 'kids'},
        {'speaker': 12, 'prompt': 'concat'},
        {'speaker': 22, 'prompt': 'concat'},
        {'speaker': 24, 'prompt': 'concat'}
    ]

    with open("../generated_audio/sentiment_alignment/top_wer/metadata.json", 'r') as f:
        sentiment_json = json.load(f)

    dataset = EmotionDataset()

    sections = [
        # {
        #     "title": "Sentiment Alignment (Male)",
        #     "description": "Emotional speech generated by a voice cloning model. Prompts are taken from the RAVDESS dataset",
        #     "table": {
        #         "headers": ["Emotion", "Audio Prompt", "This is the best day ever", "This is the worst day ever"],
        #         "content": [
        #             [
        #                 s.stem,
        #                 s,
        #                 Path("../generated_audio/sentiment_alignment/male/text_0") / s.name,
        #                 Path("../generated_audio/sentiment_alignment/male/text_1") / s.name
        #             ] for s in male_sentiments
        #         ]
        #     }
        # },
        #
        # {
        #     "title": "Sentiment Alignment (Female)",
        #     "description": "Emotional speech generated by a voice cloning model. Prompts are taken from the RAVDESS dataset",
        #     "table": {
        #         "headers": ["Emotion", "Audio Prompt", "This is the best day ever", "This is the worst day ever"],
        #         "content": [
        #             [
        #                 s.stem,
        #                 s,
        #                 Path("../generated_audio/sentiment_alignment/female/text_0") / s.name,
        #                 Path("../generated_audio/sentiment_alignment/female/text_1") / s.name
        #             ] for s in female_sentiments
        #         ]
        #     }
        # },

        # {
        #     "title": "Background Noise Alignment ",
        #     "description": "Background noise to content alignment",
        #     "table": {
        #         "headers": ["class", "laugh background noise", "phone background noise",
        #                     "waterfall background noise"],
        #         "content": [
        #             [
        #                 c,
        #                 Path(f"../generated_audio/background_noise_alignment/text_{c}") / f"laugh.wav",
        #                 Path(f"../generated_audio/background_noise_alignment/text_{c}") / f"phone.wav",
        #                 Path(f"../generated_audio/background_noise_alignment/text_{c}") / f"waterfall.wav"
        #             ] for c in classes
        #         ]
        #     }
        # },
        #
        # {
        #     "title": "Emotional Speakers Compression",
        #     "description": "Compression between different speakers in the RAVDESS dataset using XTTS voice cloning model."
        #                    " Speakers are between 1-24 (odd are men, even are women). Emotions are from ['happy', 'sad', 'neutral']",
        #     "table": {
        #         "headers": ["speaker, emotion", "audio prompt", "this is the best day ever",
        #                     "this is the worst day ever"],
        #         "content": [
        #             [
        #                 f"{emotion} - {speaker}",
        #                 dataset.get_audio_path(emotion=emotion, speaker=speaker, text='dogs'),
        #                 f"../generated_audio/sentiment_alignment/eval/eval_{emotion}-{speaker}-0.wav",
        #                 f"../generated_audio/sentiment_alignment/eval/eval_{emotion}-{speaker}-1.wav"
        #             ] for speaker in range(1, 25) for emotion in [ 'neutral', 'happy', 'sad']
        #         ]
        #     }
        # },

        # {
        #     "title": "Emotional Speakers Compression (concat prompt)",
        #     "description": "Compression between different speakers in the RAVDESS dataset using XTTS voice cloning model."
        #                    " Speakers are between 1-24 (odd are men, even are women). Emotions are from ['happy', 'sad', 'neutral']",
        #     "table": {
        #         "headers": ["speaker, emotion", "audio prompt", "this is the best day ever",
        #                     "this is the worst day ever"],
        #         "content": [
        #             [
        #                 f"{emotion} - {speaker}",
        #                 dataset.get_audio_path(emotion=emotion, speaker=speaker, text='concat'),
        #                 f"../generated_audio/sentiment_alignment/eval/eval_concat_{emotion}-{speaker}-0.wav",
        #                 f"../generated_audio/sentiment_alignment/eval/eval_concat_{emotion}-{speaker}-1.wav"
        #             ] for speaker in range(1, 25) for emotion in ['neutral', 'happy', 'sad']
        #         ]
        #     }
        # }

        {
            "title": f"sample {sample['sample']} with {text} text.",
            "description": f"{sample[f'{text}_text']}",
            "table": {
                "headers": ["speaker id", "sad sample", "happy sample"],
                "content": [
                    [
                        f"{speaker['speaker']}",
                        speaker['generated_audio'][f'sad_{text}'],
                        speaker['generated_audio'][f'happy_{text}'],

                    ] for speaker in sample['speakers']
                ]
            }
        } for sample in sentiment_json for text in ['happy', 'sad']
    ]


    html = template.render(
        page_title="Hebrew TTS",
        sections=sections

    )

    with open("index.html", 'w') as f:
        f.write(html)


if __name__ == "__main__":
    main()
