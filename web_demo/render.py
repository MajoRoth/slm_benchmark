#!/usr/bin/env python3
"""Generate forms for human evaluation."""
import json
from pathlib import Path

from jinja2 import FileSystemLoader, Environment

from utils.dataset import EmotionDataset


def main():
    """Main function."""
    loader = FileSystemLoader(searchpath="./templates")
    env = Environment(loader=loader)
    template = env.get_template("demo.html.jinja2")

    male_sentiments = list(Path("../audio/emotion_prompts/male").glob("*.wav"))
    female_sentiments = list(Path("../audio/emotion_prompts/female").glob("*.wav"))
    classes = ["laugh", "phone", "waterfall"]

    dataset = EmotionDataset()

    sections = [
        # {
        #     "title": "Sentiment Alignment (Male)",
        #     "description": "Emotional speech generated by a voice cloning model. Prompts are taken from the RAVDESS dataset",
        #     "table": {
        #         "headers": ["Emotion", "Audio Prompt", "This is the best day ever", "This is the worst day ever"],
        #         "content": [
        #             [
        #                 s.stem,
        #                 s,
        #                 Path("../generated_audio/sentiment_alignment/male/text_0") / s.name,
        #                 Path("../generated_audio/sentiment_alignment/male/text_1") / s.name
        #             ] for s in male_sentiments
        #         ]
        #     }
        # },
        #
        # {
        #     "title": "Sentiment Alignment (Female)",
        #     "description": "Emotional speech generated by a voice cloning model. Prompts are taken from the RAVDESS dataset",
        #     "table": {
        #         "headers": ["Emotion", "Audio Prompt", "This is the best day ever", "This is the worst day ever"],
        #         "content": [
        #             [
        #                 s.stem,
        #                 s,
        #                 Path("../generated_audio/sentiment_alignment/female/text_0") / s.name,
        #                 Path("../generated_audio/sentiment_alignment/female/text_1") / s.name
        #             ] for s in female_sentiments
        #         ]
        #     }
        # },

        {
            "title": "Background Noise Alignment ",
            "description": "Background noise to content alignment",
            "table": {
                "headers": ["class", "laugh background noise", "phone background noise",
                            "waterfall background noise"],
                "content": [
                    [
                        c,
                        Path(f"../generated_audio/background_noise_alignment/text_{c}") / f"laugh.wav",
                        Path(f"../generated_audio/background_noise_alignment/text_{c}") / f"phone.wav",
                        Path(f"../generated_audio/background_noise_alignment/text_{c}") / f"waterfall.wav"
                    ] for c in classes
                ]
            }
        },

        {
            "title": "Emotional Speakers Compression",
            "description": "Compression between different speakers in the RAVDESS dataset using XTTS voice cloning model."
                           " Speakers are between 1-24 (odd are men, even are women). Emotions are from ['happy', 'sad', 'neutral']",
            "table": {
                "headers": ["speaker, emotion", "audio prompt", "this is the best day ever",
                            "this is the worst day ever"],
                "content": [
                    [
                        f"{emotion} - {speaker}",
                        dataset.get_audio_path(emotion=emotion, speaker=speaker, text='dogs'),
                        f"../generated_audio/sentiment_alignment/eval/eval_{emotion}-{speaker}-0.wav",
                        f"../generated_audio/sentiment_alignment/eval/eval_{emotion}-{speaker}-1.wav"
                    ] for speaker in range(1, 25) for emotion in [ 'neutral', 'happy', 'sad']
                ]
            }
        },

        {
            "title": "Emotional Speakers Compression (concat prompt)",
            "description": "Compression between different speakers in the RAVDESS dataset using XTTS voice cloning model."
                           " Speakers are between 1-24 (odd are men, even are women). Emotions are from ['happy', 'sad', 'neutral']",
            "table": {
                "headers": ["speaker, emotion", "audio prompt", "this is the best day ever",
                            "this is the worst day ever"],
                "content": [
                    [
                        f"{emotion} - {speaker}",
                        dataset.get_audio_path(emotion=emotion, speaker=speaker, text='concat'),
                        f"../generated_audio/sentiment_alignment/eval/eval_concat_{emotion}-{speaker}-0.wav",
                        f"../generated_audio/sentiment_alignment/eval/eval_concat_{emotion}-{speaker}-1.wav"
                    ] for speaker in range(1, 25) for emotion in ['neutral', 'happy', 'sad']
                ]
            }
        }
    ]

    html = template.render(
        page_title="Hebrew TTS",
        sections=sections

    )

    with open("index.html", 'w') as f:
        f.write(html)


if __name__ == "__main__":
    main()
